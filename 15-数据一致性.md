去重问题，Mergetree也只保证最终一致性

replacingMergeTree 会去重，但只在合并时发生，也不保证没有重复数据

## 去重实验

create table test_a(
    user_id UInt64,
    score String,
    deleted UInt8 default 0,
    create_time DateTime default toDateTime(0)
)engine = ReplacingMergeTree (create_time)
    order by user_id;

user_id是数据去重更新的标识，

写入1000万测试数据：  
insert into table test_a(user_id, score) 
with(
    select ['A', 'B', 'C', 'D', 'E', 'F', 'G']
) as dict 
select number as user_id, dict[number%7+1] from numbers(10000000);  

修改前50万行数据：  
insert into table test_a(user_id, score, create_time) 
with(
    select ['AA', 'BB', 'CC', 'DD', 'EE', 'FF', 'GG']
)as dict 
select number as user_id, dict[number%7+1], now() as create_time from numbers(500000);

统计总数：  
select count() from test_a;
可以看到还没合并，手动合并一下：  
optimize table test_a final;  
再查时已经合并了：  
┌──count()─┐
│ 10000000 │
└──────────┘

## 通过group by去重

1、重新插入50万条  
2、group by查询：  
select 
    user_id,
    argMax(score, create_time) as score,
    argMax(deleted, create_time) as deleted,
    max(create_time) as ctime 
from test_a 
    group by user_id 
    having deleted = 0;

argMax时间最大，就是最新 
argMax(field1, field2) 按照field2的最大值取field1的值  

## 更新删除测试

更新删除用视图+标记实现

创建视图（视图不存数据，只存操作逻辑）：  
create view view_test_a as 
select 
    user_id,
    argMax(score, create_time) as score,
    argMax(deleted, create_time) as deleted,
    max(create_time) as ctime 
from test_a 
    group by user_id
    having deleted = 0;

插入重复数据，再次查询：  
insert into table test_a(user_id, score, create_time) 
values(0, 'AAAA', now());

select count(*) from test_a;
┌──count()─┐
│ 10500001 │
└──────────┘

再次查询：  
select * from view_test_a where user_id=0;
┌─user_id─┬─score─┬─deleted─┬───────────────ctime─┐
│       0 │ AAAA  │       0 │ 2022-05-21 10:17:37 │
└─────────┴───────┴─────────┴─────────────────────┘

原来数据：  
select * from test_a where user_id=0;
┌─user_id─┬─score─┬─deleted─┬─────────create_time─┐
│       0 │ AA    │       0 │ 2022-05-21 08:40:54 │
└─────────┴───────┴─────────┴─────────────────────┘
┌─user_id─┬─score─┬─deleted─┬─────────create_time─┐
│       0 │ AA    │       0 │ 2022-05-21 09:22:09 │
└─────────┴───────┴─────────┴─────────────────────┘
┌─user_id─┬─score─┬─deleted─┬─────────create_time─┐
│       0 │ AAAA  │       0 │ 2022-05-21 10:17:37 │
└─────────┴───────┴─────────┴─────────────────────┘
可以看到只保留了user_id最新的一条

## 通过final查询

以前合并后才能的查询加上final单独做一次去重  

以下实验证明新版本final支持多线程
use datasets;  
explain pipeline select * from visits_v1 where StartDate = '2014-03-17' 
limit 100 settings max_threads = 2; 

加上final：  
explain pipeline select * from visits_v1 final where StartDate = '2014-03-17' 
limit 100 settings max_threads = 2; 

## 总结

repllacingMergeTree不能保证查询时没重复，只能保证最终一致性  
解决方案：
    1、手动执行：生产环境不推荐  
    2、sql去重，group by -> 高级用法：加标记  
    3、使用final  
    4、重复一点无所谓  